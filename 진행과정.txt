실험 설계

1. 이동성 예측
- Baseline 1 (RNN/LSTM):
기존 서베이 논문 레퍼런스 방식대로 구성
- Proposed (Transformer):
Self-Attention 기반 구조-시계열 데이터에 맞게
=> 두 모델의 예측 오차와 연결 끊김 예측 정확도 등 예상 결과를 비교

2. DRL 에이전트 결합 및 오프로딩 실험
- Senario A: 현재 상태만으로 수행
- Senario B: with LSTM
- Senario C: with Transformer

(1) SUMO 설치
(2) 지도 및 교통량 생성 (OSM Web Wizard)
(3) Python 연동 (TraCI)

--------------------------------------

# test_env.py: 가상 환경 테스트
# data_collector.py: 시뮬레이션을 3600스텝(약 1시간) 동안 돌리면서, 도로 위 모든 차량의 위치(x, y)와 속도를 1초 단위로 기록
(1) 실행 시 뜨는 SUMO GUI 창의 위쪽 Play 버튼 누르면 시뮬레이션 시작
(2) 차량이 움직이는 게 보여야 함
(3) 지정된 시간(3600스텝)이 지나면 창이 닫히고 mobility_dataset.csv 파일이 생성됨

--------------------------------------

1. 이동성 예측
- Baseline 1 (RNN/LSTM)
- Proposed (Transformer)
: mobility_dataset.csv 데이터셋 기반 예측 모델 성능 테스트(LSTM_predictor / Transformer_predictor)

# lstm_predictor.py
# Transformer_predictor.py

[예상 결과]
- LSTM: 학습은 빠르나 복잡한 경로 등 상대적으로 더 높은 Loss 예상
- Transformer: 학습 초반에는 느리나 최종적으로는 더 낮은 Loss(더 정확) 예상

[LSTM] 데이터셋 로드 완료. 총 샘플 수: 28645
>>> Training Start (Baseline: LSTM)
Epoch [5/30], Loss: 197085.356881
Epoch [10/30], Loss: 119988.706665
Epoch [15/30], Loss: 74468.765555
Epoch [20/30], Loss: 48632.504512
Epoch [25/30], Loss: 30545.497210
Epoch [30/30], Loss: 17362.520950
>>> LSTM Training Finished.

[Transformer] 데이터셋 로드 완료. 총 샘플 수: 28645
>>> Training Start (Proposed: Transformer)
Epoch [5/30], Loss: 40128.272330
Epoch [10/30], Loss: 10630.544478
Epoch [15/30], Loss: 3133.509059
Epoch [20/30], Loss: 2212.586434
Epoch [25/30], Loss: 1420.070494
Epoch [30/30], Loss: 1432.270480
>>> Transformer Training Finished.

실험 결과, 의도한 대로 proposed model(Transformer 기반 예측 모델)의 우수성 증명됨

결과 분석
- Baseline(LSTM): 최종 Loss 약 17362
- Proposed(Transformer): 최종 Loss 약 1432
결론적으로, Transformer 모델이 LSTM보다 약 12배 더 낮은 오차를 기록
Self-Attention 기반 Transformer가 차량의 과거 주행 패턴을 더 잘 파악하여 미래 위치를 정밀하고 정확하게 예측함

--------------------------------------

2. SUMO와 PPO 연동을 통한 DRL 기반 Offloading 성능 실험
- Scenario A (No Prediction): 현재 정보만 보고 결정.
- Scenario B (LSTM): LSTM이 예측한 미래 정보를 보고 결정.
- Scenario C (Transformer): Transformer가 예측한 미래 정보를 보고 결정.

# train_models_normalized.py
# RL_exp.py

[예상 결과]
A(회색): 점수가 가장 낮음 (예측 없이 마구잡이로 오프로딩하다가 연결이 끊겨 패널티를 많이 받음)
B(파란색): 점수가 중간 (LSTM이 어느 정도 예측해서 끊김을 방지함)
C(빨간색): 점수가 가장 높음 (Transformer가 더 정확하게 예측하여 연결이 유지될 때만 똑똑하게 오프로딩함)
