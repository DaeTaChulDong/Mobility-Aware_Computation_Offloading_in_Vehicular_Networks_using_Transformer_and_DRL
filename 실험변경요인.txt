1. 데이터 정규화 문제

- SUMO의 좌표값이 0~1000으로 너무 크므로 데이터 정규화 필요(1000으로 나누기)
- 데이터 정규화(Normalization)의 부재로 인한 문제 해결 목적
# train_models_normalized.py: 데이터 정규화 적용하여 예측 모델 재학습

--------------------------------------

2. 지역 최적점 문제와 보상 체계 불균형

- 현재 설정을 다음과 같이 변경: Offloading을 권장하는 방향으로 변경
(1) 성공 (+10) -> (+20)
(2) 실패 (-10) -> (-10)
(3) 로컬 (-2) -> (-1)
- Local Optima(지역 최적점) 문제와 보상 체계(Reward Shaping)의 불균형 해결 목적
- 실패의 패널티가 너무 커 로컬을 선택하게 되는 학습 체계 개선
- 에피소드 수 증가: 3회 -> 5회

# train_best_models.py: 보상 체계를 변경하여 모델 재학습

--------------------------------------

3. 긴 시간 후의 예측에 대한 정확성 반영

- 더 긴 시간 후의 예측에 대한 정확성 반영을 위해 작업 시간을 10초로 변경
- LSTM과 Transformer간 긴 시간 후의 예측에 대한 유의미한 성능 차이 관찰 목적

# train_hard_mode.py: 더 긴 기간을 예측하도록 모델을 재학습
# RL_exp.py: 작업 시간(Output Window)이 긴(10초) 환경에서 실험

[예상 결과]
상대적으로 LSTM 모델의 점수는 떨어지거나 정체될 것이고, Transformer 모델은 정확도를 유지하여 점수 차이의 간극 심화될 것으로 예상

--------------------------------------

4. MGCO 벤치마킹 및 논문의 환경에 가깝게 하여 재실험

- MGCO 논문의 생성형 오프로딩(Generative Offloading) 개념을 State Space 확장으로 구현
- Transformer가 단순한 좌표 예측뿐 아닌 PPO 에이전트에게 미래의 불확실성과 맥락(Context Vector/Hidden State)까지 직접 전달하도록 함

# train_fusion_models.py: 예측 모델이 예측값과 특징 벡터를 모두 출력할 수 있도록 모델 재학습
# RL_exp.py: 실행 PPO 에이전트가 Transformer의 특징 벡터를 공유받아 실험 수행(PPO 에이전트의 State Space를 확장하여 예측 모델의 특징 벡터(64차원)을 받아들이도록 함)

--------------------------------------

5. 실패했을 때의 패널티를 아주 크게 하고 데이터셋의 복잡도를 높여 재실험

- 통신이 끊겼을 때의 reward를 -10에서 -100으로 대폭 증가
- 데이터셋의 복잡도를 단순 직선과 적은 교통량에서 Manhattan의 복잡한 교차로로 변경

# previous_mobility_dataset.csv(신촌) -> # mobility_dataset.cvs(Manhattan)

--------------------------------------

6. 파라미터 변경

- 입출력 길이 확장: 과거 10초->30초, 미래 5초->15초로 변경하여 장기적인 패턴 학습하도록 변경
- 모델 용량 증대: 레이어와 헤드 수를 변경하여 복잡한 패턴 학습하도록 변경
- Feature Extraction: RL 에이전트에게 단순 예측값뿐만 아니라 판단의 근거(Feature Vector)까지 넘겨줄 수 있도록 구조를 업그레이드

--------------------------------------

7. PPO 학습 과정 대신 모델의 예측 능력 차이만을 검증

- 현재 환경으로 실험 가능한 에피소드 수가 너무 적어 제대로 PPO 훈련이 불가
- Transformer에서 더 많은 레이어와 복잡한 조건은 정확도를 낮출 수 있음
- Precision Bonus 도입을 통해 예측에 대한 정확도에 대해 보너스를 추가

# model_verift_performance.py: PPO 학습 여부와 상관없이 "모델의 예측 성능"이 오프로딩 효율에 얼마나 기여하는지를 직접적으로 증명